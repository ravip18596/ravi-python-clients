[[package]]
name = "delta-spark"
version = "1.2.1"
description = "Python APIs for using Delta Lake with Apache Spark"
category = "main"
optional = false
python-versions = ">=3.6"

[package.dependencies]
importlib-metadata = ">=1.0.0"
pyspark = ">=3.2.0,<3.3.0"

[[package]]
name = "importlib-metadata"
version = "4.11.4"
description = "Read metadata from Python packages"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
zipp = ">=0.5"

[package.extras]
docs = ["sphinx", "jaraco.packaging (>=9)", "rst.linker (>=1.9)"]
perf = ["ipython"]
testing = ["pytest (>=6)", "pytest-checkdocs (>=2.4)", "pytest-flake8", "pytest-cov", "pytest-enabler (>=1.0.1)", "packaging", "pyfakefs", "flufl.flake8", "pytest-perf (>=0.9.2)", "pytest-black (>=0.3.7)", "pytest-mypy (>=0.9.1)", "importlib-resources (>=1.3)"]

[[package]]
name = "py4j"
version = "0.10.9.3"
description = "Enables Python programs to dynamically access arbitrary Java objects"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "pyspark"
version = "3.2.1"
description = "Apache Spark Python API"
category = "main"
optional = false
python-versions = ">=3.6"

[package.dependencies]
py4j = "0.10.9.3"

[package.extras]
ml = ["numpy (>=1.7)"]
mllib = ["numpy (>=1.7)"]
pandas_on_spark = ["numpy (>=1.14)", "pandas (>=0.23.2)", "pyarrow (>=1.0.0)"]
sql = ["pandas (>=0.23.2)", "pyarrow (>=1.0.0)"]

[[package]]
name = "zipp"
version = "3.8.0"
description = "Backport of pathlib-compatible object wrapper for zip files"
category = "main"
optional = false
python-versions = ">=3.7"

[package.extras]
docs = ["sphinx", "jaraco.packaging (>=9)", "rst.linker (>=1.9)"]
testing = ["pytest (>=6)", "pytest-checkdocs (>=2.4)", "pytest-flake8", "pytest-cov", "pytest-enabler (>=1.0.1)", "jaraco.itertools", "func-timeout", "pytest-black (>=0.3.7)", "pytest-mypy (>=0.9.1)"]

[metadata]
lock-version = "1.1"
python-versions = "^3.8"
content-hash = "ffcd52b81c81e4185db4a6a6274a2652d11383868db0d5e6e95c22125f9b1fdc"

[metadata.files]
delta-spark = [
    {file = "delta-spark-1.2.1.tar.gz", hash = "sha256:1c218acbd9a6d1aa0c8637735d6b69593f3ff38123c6123afd268d76ac74ef8e"},
    {file = "delta_spark-1.2.1-py3-none-any.whl", hash = "sha256:96369c352c6a7468ed8074acf5af86c94eaf4f5065529284c74cc98fa0ae6761"},
]
importlib-metadata = [
    {file = "importlib_metadata-4.11.4-py3-none-any.whl", hash = "sha256:c58c8eb8a762858f49e18436ff552e83914778e50e9d2f1660535ffb364552ec"},
    {file = "importlib_metadata-4.11.4.tar.gz", hash = "sha256:5d26852efe48c0a32b0509ffbc583fda1a2266545a78d104a6f4aff3db17d700"},
]
py4j = [
    {file = "py4j-0.10.9.3-py2.py3-none-any.whl", hash = "sha256:04f5b06917c0c8a81ab34121dda09a2ba1f74e96d59203c821d5cb7d28c35363"},
    {file = "py4j-0.10.9.3.tar.gz", hash = "sha256:0d92844da4cb747155b9563c44fc322c9a1562b3ef0979ae692dbde732d784dd"},
]
pyspark = [
    {file = "pyspark-3.2.1.tar.gz", hash = "sha256:0b81359262ec6e9ac78c353344e7de026027d140c6def949ff0d80ab70f89a54"},
]
zipp = [
    {file = "zipp-3.8.0-py3-none-any.whl", hash = "sha256:c4f6e5bbf48e74f7a38e7cc5b0480ff42b0ae5178957d564d18932525d5cf099"},
    {file = "zipp-3.8.0.tar.gz", hash = "sha256:56bf8aadb83c24db6c4b577e13de374ccfb67da2078beba1d037c17980bf43ad"},
]
